{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('local[*]')\\\n",
    "        .appName('MvT')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = open('afinn-111.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = afinn.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abandon\\t-2\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon', '-2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\t|\\n', sample)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDict(file):\n",
    "    file.seek(0)\n",
    "    sentDict = {}\n",
    "    while True:\n",
    "        nxt = file.readline()\n",
    "        if nxt != '':\n",
    "            splt = re.split(r'\\t|\\n', nxt)\n",
    "            if len(splt) == 3:\n",
    "                splt = splt[:-1]\n",
    "            sentDict[splt[0]] = int(splt[1])\n",
    "        else:\n",
    "            break\n",
    "    return sentDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentDict = cleanDict(afinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional POS Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/spring2021/project1/comparison/Charles Dickens - Cities.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "startin = raw.find(\" ***\") + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "endin = raw.rfind(\"End of the Project Gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw[startin:endin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w.lower() for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "for word in words:\n",
    "    if word in list(sentDict.keys()):\n",
    "        score += sentDict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-359"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreTrad(raw):\n",
    "        startin = raw.find(\" ***\") + 4\n",
    "        endin = raw.rfind(\"End of the Project Gutenberg\")\n",
    "        raw = raw[startin:endin]\n",
    "        tokens = nltk.word_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        words = [w.lower() for w in text]\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        for word in words:\n",
    "            if word in list(sentDict.keys()):\n",
    "                score += sentDict[word]\n",
    "                \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('/spring2021/project1/comparison/Charles Dickens - Cities.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('/spring2021/project1/comparison/Conan Doyle - Sherlock.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open('/spring2021/project1/comparison/Herman Melville - Moby.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = open('/spring2021/project1/comparison/Jane Austen - Pride.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f5 = open('/spring2021/project1/comparison/Mary Shelley - Frankenstein.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f6 = open('/spring2021/project1/comparison/Nathaniel Hawthorne - Scarlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f7 = open('/spring2021/project1/comparison/Scott Fitzgerald - Gatsby.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradRaws = [f.read() for f in [f1, f2, f3, f4, f5, f6, f7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradScores = [scoreTrad(r) for r in tradRaws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-359, 313, 1317, 3898, 60, 630, 230]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avg Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869.8571428571429"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = sum(tradScores)/len(tradScores)\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-359, 3898)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(min(tradScores),max(tradScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326.2505073187588"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(sum([(x-mu)**2 for x in tradScores])/len(tradScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog Text POS Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogDF = spark.read.csv('/spring2021/project1/blogtext.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+-----------------+--------+------------+--------------------+\n",
      "|     id|gender|age|            topic|    sign|        date|                text|\n",
      "+-------+------+---+-----------------+--------+------------+--------------------+\n",
      "|2059027|  male| 15|          Student|     Leo| 14,May,2004|           Info h...|\n",
      "|2059027|  male| 15|          Student|     Leo| 13,May,2004|           These ...|\n",
      "|2059027|  male| 15|          Student|     Leo| 12,May,2004|           In het...|\n",
      "|2059027|  male| 15|          Student|     Leo| 12,May,2004|           testin...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|11,June,2004|             Than...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|10,June,2004|             I ha...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|10,June,2004|             Some...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|10,June,2004|             If a...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|10,June,2004|             Take...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|             I su...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|             Ah, ...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|             If y...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|             Last...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|             Ther...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|              url...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|             One ...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|09,June,2004|              url...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|18,June,2004|             Here...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|17,June,2004|             Well...|\n",
      "|3581210|  male| 33|InvestmentBanking|Aquarius|16,June,2004|             So I...|\n",
      "+-------+------+---+-----------------+--------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogRDD = blogDF.select('text').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapScore(x):\n",
    "    raw = x['text']\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    text = nltk.Text(tokens)\n",
    "    words = [w.lower() for w in text]\n",
    "\n",
    "    score = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in list(sentDict.keys()):\n",
    "            score += sentDict[word]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreRDD = blogRDD.map(mapScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200179"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulScore = scoreRDD.reduce(add)\n",
    "cumulScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgMap(x):\n",
    "    return (x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgRed(x,y):\n",
    "    return (x[0] + y[0], x[1] + y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRDD = scoreRDD.map(avgMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgTup = avgRDD.reduce(avgRed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200179, 681284)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgTup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = avgTup[0]/avgTup[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.697276025857058"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowRng = scoreRDD.reduce(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "upperRng = scoreRDD.reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3551, 6034)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lowRng, upperRng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdMap(x):\n",
    "    return (x**2,x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogSD = scoreRDD.map(sdMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogSdTup = blogSD.reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = np.sqrt((blogSdTup[0]/blogSdTup[2]) + ((blogSdTup[1]**2)/blogSdTup[2]))\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why can't I turn this into a dataframe??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField, IntegerType\n",
    "\n",
    "schema = StructType([StructField(\"Score\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreDF = spark.createDataFrame(scoreRDD, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scoreDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker POS Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackDF = spark.read.csv('/spring2021/project1/hacker_news_sample.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----+---------------+-----+----------+-------+--------+--------+-----------+-------+-------+-------------------+\n",
      "|               title|                 url|                text|dead|             by|score|      time|   type|      id|  parent|descendants|ranking|deleted|          timestamp|\n",
      "+--------------------+--------------------+--------------------+----+---------------+-----+----------+-------+--------+--------+-----------+-------+-------+-------------------+\n",
      "|                null|                null|&gt;<i>which lead...|null|        coldtea| null|1390843873|comment| 7131680| 7127578|       null|   null|   null|2014-01-27 12:31:13|\n",
      "|                null|                null|I would like to p...|null|         etanol| null|1319395600|comment| 3146879| 3145330|       null|   null|   null|2011-10-23 14:46:40|\n",
      "|                null|                null|                null|null|           null| null|1456640816|comment|11190089|11189361|       null|   null|   True|2016-02-28 01:26:56|\n",
      "|                null|                null|<i>Our msbuild im...|null|      Locke1689| null|1407881590|comment| 8170491| 8170071|       null|   null|   null|2014-08-12 18:13:10|\n",
      "|                null|                null|No matter how awf...|null|    miloshadzic| null|1362572882|comment| 5330773| 5327590|       null|   null|   null|2013-03-06 07:28:02|\n",
      "|                null|                null|The existence of ...|null|      salsakran| null|1302987863|comment| 2454827| 2452073|       null|   null|   null|2011-04-16 17:04:23|\n",
      "|       #McConnelling|http://www.mcconn...|                null|null|  deepblueocean|    2|1395179086|  story| 7425232|    null|          0|   null|   null|2014-03-18 17:44:46|\n",
      "|A floating self-s...|http://www.kickst...|                null|null|         tudorw|    1|1353326078|  story| 4803967|    null|          0|   null|   null|2012-11-19 06:54:38|\n",
      "|What Ever Happene...|https://backchann...|                null|null|      mirandak4|    2|1478267730|  story|12872547|    null|          0|   null|   null|2016-11-04 09:55:30|\n",
      "|                null|                null|The actual Intern...|null|     paulsutter| null|1467500087|comment|12024085|12023632|       null|   null|   null|2016-07-02 18:54:47|\n",
      "|                null|                null|I want to know ho...|null|        sitkack| null|1398706338|comment| 7661504| 7661268|       null|   null|   null|2014-04-28 13:32:18|\n",
      "|                null|                null|French is supreme...|True|    cjsthompson| null|1448732039|comment|10641694|10641458|       null|   null|   null|2015-11-28 12:33:59|\n",
      "|                null|                null|I actually went f...|null|          evgen| null|1495398162|comment|14389061|14385039|       null|   null|   null|2017-05-21 16:22:42|\n",
      "|                null|                null|First impression ...|null|     adventured| null|1360209122|comment| 5180426| 5180196|       null|   null|   null|2013-02-06 22:52:02|\n",
      "|                null|                null|It&#x27;s not exa...|null|      jhanschoo| null|1453802012|comment|10972639|10967607|       null|   null|   null|2016-01-26 04:53:32|\n",
      "|                null|                null|Thanks. I choose ...|null|       greggman| null|1446247482|comment|10481148|10476753|       null|   null|   null|2015-10-30 19:24:42|\n",
      "|                null|                null|                null|null|           null| null|1466136395|comment|11920638|11920160|       null|   null|   True|2016-06-17 00:06:35|\n",
      "|Epic Privacy Brow...|https://www.epicb...|                null|null|          sinak|    1|1424799729|  story| 9102174|    null|          0|   null|   null|2015-02-24 12:42:09|\n",
      "|                null|                null|I used Sybase ASE...|null|lobster_johnson| null|1482010908|comment|13202822|13200461|       null|   null|   null|2016-12-17 16:41:48|\n",
      "|                null|                null|&gt;They&#x27;ve ...|null|   shrimp_emoji| null|1492696939|comment|14156673|14156630|       null|   null|   null|2017-04-20 10:02:19|\n",
      "+--------------------+--------------------+--------------------+----+---------------+-----+----------+-------+--------+--------+-----------+-------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hackDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackRDD = hackDF.select('text').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def mapScoreHTML(x):\n",
    "    if x['text'] != None:\n",
    "        bs = BeautifulSoup(x['text'], 'lxml')\n",
    "        raw = bs.get_text()\n",
    "        tokens = nltk.word_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        words = [w.lower() for w in text]\n",
    "\n",
    "        score = 0\n",
    "\n",
    "        for word in words:\n",
    "            if word in list(sentDict.keys()):\n",
    "                score += sentDict[word]\n",
    "    else:\n",
    "        score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreHackRDD = hackRDD.map(mapScoreHTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221504"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulScoreHack = scoreHackRDD.reduce(add)\n",
    "cumulScoreHack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgMap(x):\n",
    "    return (x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgRed(x,y):\n",
    "    return (x[0] + y[0], x[1] + y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgHackRDD = scoreHackRDD.map(avgMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgHackTup = avgHackRDD.reduce(avgRed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221504, 215067)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgHackTup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = avgHackTup[0]/avgHackTup[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0299302077957102"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowRngHack = scoreHackRDD.reduce(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "upperRngHack = scoreHackRDD.reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-105, 124)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lowRngHack, upperRngHack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdMap(x):\n",
    "    return (x**2,x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackSD = scoreHackRDD.map(sdMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackSdTup = hackSD.reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.142135623730951"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = np.sqrt((hackSdTup[0]/hackSdTup[2]) + ((hackSdTup[1]**2)/hackSdTup[2]))\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c6b4d5d9db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
